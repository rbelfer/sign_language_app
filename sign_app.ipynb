{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import joblib\n",
    "import time\n",
    "import os, sys\n",
    "from random import random\n",
    "from english_words import english_words_lower_alpha_set\n",
    "from flask import Flask, render_template, Response, request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global easy, medium, hard, freestyle, switch\n",
    "easy=0\n",
    "medium=0\n",
    "hard=0\n",
    "freestyle=0\n",
    "switch=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(\"random_forest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__, template_folder='./template')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR CONVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "    \n",
    "def get_landmark_dist_test(results, x, y):\n",
    "    hand_array = []\n",
    "    wrist_pos = results.multi_hand_landmarks[0].landmark[0]\n",
    "    for result in results.multi_hand_landmarks[0].landmark:\n",
    "        hand_array.append((result.x-wrist_pos.x) * (width/x))\n",
    "        hand_array.append((result.y-wrist_pos.y) * (height/y))\n",
    "    return(hand_array[2:])\n",
    "\n",
    "def camera_max():\n",
    "    #Returns int value of available camera devices connected to the host device\n",
    "    camera = 0\n",
    "    while True:\n",
    "        if (cv2.VideoCapture(camera).grab()):\n",
    "            camera = camera + 1\n",
    "        else:\n",
    "            cv2.destroyAllWindows()\n",
    "            return(max(0,int(camera-1)))\n",
    "\n",
    "words = [i for i in sorted(list(english_words_lower_alpha_set)) if 'z' not in i and len(i) > 3 and len(i) <= 10]\n",
    "start_time = time.time()\n",
    "curr_time = 0\n",
    "easy_word_user = ''\n",
    "eraser = 0\n",
    "easy_word = words[int(random()*len(words))].upper()\n",
    "easy_word_index = 0\n",
    "letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "\n",
    "#Main function\n",
    "cap = cv2.VideoCapture(camera_max())\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Set mediapipe model\n",
    "mp_hands = mp.solutions.hands # Hands model\n",
    "with mp_hands.Hands(min_detection_confidence=0.6, min_tracking_confidence=0.6, max_num_hands=1) as hands:\n",
    "    while cap.isOpened():\n",
    " \n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        try:\n",
    "            cv2.putText(frame, easy_word, (int(width*0.05), int(height*0.95)), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_4)\n",
    "            cv2.putText(frame, easy_word_user, (int(width*0.05), int(height*0.95)), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2, cv2.LINE_4)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    " \n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, hands)\n",
    "        \n",
    "        letter_help = cv2.resize(cv2.imread('easy_mode_letters/{}.png'.format(easy_word[easy_word_index].lower())), (0,0), fx=0.2, fy=0.2)\n",
    "         \n",
    "        #Find bounding box of hand\n",
    "        if results.multi_hand_landmarks:\n",
    "            x = [None,None]\n",
    "            y=[None,None]\n",
    "            for result in results.multi_hand_landmarks[0].landmark:\n",
    "                if x[0] is None or result.x < x[0]: x[0] = result.x\n",
    "                if x[1] is None or result.x > x[1]: x[1] = result.x\n",
    "\n",
    "                if y[0] is None or result.y < y[0]: y[0] = result.y\n",
    "                if y[1] is None or result.y > y[1]: y[1] = result.y\n",
    "\n",
    "            \n",
    "            if curr_time < round((time.time() - start_time)/3,1) and x[0] is not None:\n",
    "                    curr_time = round((time.time() - start_time)/3,1)\n",
    "                    try:\n",
    "                        test_image = get_landmark_dist_test(results, x[1]-x[0], y[1]-y[0])\n",
    "                        test_pred = np.argmax(clf.predict_proba(np.array([test_image])))\n",
    "                        test_probs = clf.predict_proba(np.array([test_image]))[0]\n",
    "                        if max(test_probs) >= 0.8 or (max(test_probs) >= 0.6 and letters[test_pred] in ['r','v']):\n",
    "                            pred_letter = letters[test_pred].upper()\n",
    "                            if easy_word_index < len(easy_word) and pred_letter == easy_word[easy_word_index] and (easy_word_index == 0 or easy_word[easy_word_index] != easy_word[easy_word_index - 1]):\n",
    "                                easy_word_user += pred_letter\n",
    "                                easy_word_index += 1\n",
    "                                location = results.multi_hand_landmarks[0].landmark[0].x\n",
    "                            if easy_word_index < len(easy_word) and pred_letter == easy_word[easy_word_index] and easy_word_index > 0 and easy_word[easy_word_index] == easy_word[easy_word_index - 1] and abs(location - results.multi_hand_landmarks[0].landmark[0].x) > 0.1:\n",
    "                                easy_word_user += pred_letter\n",
    "                                easy_word_index += 1\n",
    "                                location = results.multi_hand_landmarks[0].landmark[0].x\n",
    "                        \n",
    "                        if easy_word_user == easy_word:\n",
    "                            time.sleep(0.5)\n",
    "                            easy_word = words[int(random()*len(words))].upper()\n",
    "                            easy_word_index = 0\n",
    "                            easy_word_user = ''\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                \n",
    "        # Show to screen\n",
    "        frame[5:5+letter_help.shape[0],width-5-letter_help.shape[1]:width-5] = letter_help\n",
    "        cv2.imshow('OpenCV Feed', frame)\n",
    "        \n",
    "\n",
    "        # Break gracefully\n",
    "        key = cv2.waitKey(20)\n",
    "        if key == 27:\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_max():\n",
    "    '''Returns int value of available camera devices connected to the host device'''\n",
    "    camera = 0\n",
    "    while True:\n",
    "        if (cv2.VideoCapture(camera).grab()):\n",
    "            camera = camera + 1\n",
    "        else:\n",
    "            cv2.destroyAllWindows()\n",
    "            return(max(0,int(camera-1)))\n",
    "        \n",
    "cam_max = camera_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(cam_max, cv2.CAP_DSHOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "words = [i for i in sorted(list(english_words_lower_alpha_set)) if 'z' not in i and len(i) > 3 and len(i) <= 10]\n",
    "start_time = time.time()\n",
    "curr_time = 0\n",
    "easy_word_user = ''\n",
    "eraser = 0\n",
    "easy_word = words[int(random()*len(words))].upper()\n",
    "easy_word_index = 0\n",
    "location = 0\n",
    "letter_help = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_mode(frame):\n",
    "    global cap, easy_word_user, easy_word, easy_word_index, curr_time, location, letter_help\n",
    "    \n",
    "    def mediapipe_detection(image, model):\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "        results = model.process(image)                 # Make prediction\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR CONVERSION RGB 2 BGR\n",
    "        return image, results\n",
    "\n",
    "    def get_landmark_dist_test(results, x, y):\n",
    "        hand_array = []\n",
    "        wrist_pos = results.multi_hand_landmarks[0].landmark[0]\n",
    "        for result in results.multi_hand_landmarks[0].landmark:\n",
    "            hand_array.append((result.x-wrist_pos.x) * (width/x))\n",
    "            hand_array.append((result.y-wrist_pos.y) * (height/y))\n",
    "        return(hand_array[2:])\n",
    "\n",
    "\n",
    "    #Main function\n",
    "    #cap = cv2.VideoCapture(cam_max)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Set mediapipe model\n",
    "    mp_hands = mp.solutions.hands # Hands model\n",
    "    with mp_hands.Hands(min_detection_confidence=0.6, min_tracking_confidence=0.6, max_num_hands=1) as hands:\n",
    "        while cap.isOpened():\n",
    "\n",
    "            # Read feed\n",
    "            #ret, frame = cap.read()\n",
    "\n",
    "            try:\n",
    "                cv2.putText(frame, easy_word, (int(width*0.05), int(height*0.95)), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_4)\n",
    "                cv2.putText(frame, easy_word_user, (int(width*0.05), int(height*0.95)), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2, cv2.LINE_4)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "            # Make detections\n",
    "            image, results = mediapipe_detection(frame, hands)\n",
    "\n",
    "            letter_help = cv2.resize(cv2.imread('easy_mode_letters/{}.png'.format(easy_word[easy_word_index].lower())), (0,0), fx=0.2, fy=0.2)\n",
    "\n",
    "            #Find bounding box of hand\n",
    "            if results.multi_hand_landmarks:\n",
    "                x = [None,None]\n",
    "                y=[None,None]\n",
    "                for result in results.multi_hand_landmarks[0].landmark:\n",
    "                    if x[0] is None or result.x < x[0]: x[0] = result.x\n",
    "                    if x[1] is None or result.x > x[1]: x[1] = result.x\n",
    "\n",
    "                    if y[0] is None or result.y < y[0]: y[0] = result.y\n",
    "                    if y[1] is None or result.y > y[1]: y[1] = result.y\n",
    "\n",
    "\n",
    "                if curr_time < round((time.time() - start_time)/3,1) and x[0] is not None:\n",
    "                        curr_time = round((time.time() - start_time)/3,1)\n",
    "                        try:\n",
    "                            test_image = get_landmark_dist_test(results, x[1]-x[0], y[1]-y[0])\n",
    "                            test_pred = np.argmax(clf.predict_proba(np.array([test_image])))\n",
    "                            test_probs = clf.predict_proba(np.array([test_image]))[0]\n",
    "                            print(\"Predicted:\",letters[test_pred], \", pred prob:\", max(test_probs), \", current index:\", easy_word_index, \", current time:\", curr_time)\n",
    "                            if max(test_probs) >= 0.8 or (max(test_probs) >= 0.6 and letters[test_pred] in ['p','r','u','v']):\n",
    "                                pred_letter = letters[test_pred].upper()\n",
    "                                if easy_word_index < len(easy_word) and pred_letter == easy_word[easy_word_index] and (easy_word_index == 0 or easy_word[easy_word_index] != easy_word[easy_word_index - 1]):\n",
    "                                    easy_word_user += pred_letter\n",
    "                                    easy_word_index += 1\n",
    "                                    location = results.multi_hand_landmarks[0].landmark[0].x\n",
    "                                if easy_word_index < len(easy_word) and pred_letter == easy_word[easy_word_index] and easy_word_index > 0 and easy_word[easy_word_index] == easy_word[easy_word_index - 1] and abs(location - results.multi_hand_landmarks[0].landmark[0].x) > 0.1:\n",
    "                                    easy_word_user += pred_letter\n",
    "                                    easy_word_index += 1\n",
    "                                    location = results.multi_hand_landmarks[0].landmark[0].x\n",
    "\n",
    "                            if easy_word_user == easy_word:\n",
    "                                time.sleep(0.5)\n",
    "                                easy_word = words[int(random()*len(words))].upper()\n",
    "                                easy_word_index = 0\n",
    "                                easy_word_user = ''\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "\n",
    "            # Show letter helper\n",
    "            frame[5:5+letter_help.shape[0],width-5-letter_help.shape[1]:width-5] = letter_help\n",
    "\n",
    "            return frame\n",
    "            \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medium_mode(frame):\n",
    "    global cap, easy_word_user, easy_word, easy_word_index, curr_time, location, letter_help\n",
    "    \n",
    "    def mediapipe_detection(image, model):\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "        results = model.process(image)                 # Make prediction\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR CONVERSION RGB 2 BGR\n",
    "        return image, results\n",
    "\n",
    "    def get_landmark_dist_test(results, x, y):\n",
    "        hand_array = []\n",
    "        wrist_pos = results.multi_hand_landmarks[0].landmark[0]\n",
    "        for result in results.multi_hand_landmarks[0].landmark:\n",
    "            hand_array.append((result.x-wrist_pos.x) * (width/x))\n",
    "            hand_array.append((result.y-wrist_pos.y) * (height/y))\n",
    "        return(hand_array[2:])\n",
    "    \n",
    "    #Main function\n",
    "    #cap = cv2.VideoCapture(cam_max)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Set mediapipe model\n",
    "    mp_hands = mp.solutions.hands # Hands model\n",
    "    with mp_hands.Hands(min_detection_confidence=0.6, min_tracking_confidence=0.6, max_num_hands=1) as hands:\n",
    "        while cap.isOpened():\n",
    "\n",
    "            # Read feed\n",
    "            #ret, frame = cap.read()\n",
    "\n",
    "            try:\n",
    "                cv2.putText(frame, easy_word, (int(width*0.05), int(height*0.95)), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_4)\n",
    "                cv2.putText(frame, easy_word_user, (int(width*0.05), int(height*0.95)), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2, cv2.LINE_4)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "            # Make detections\n",
    "            image, results = mediapipe_detection(frame, hands)\n",
    "\n",
    "            #Find bounding box of hand\n",
    "            if results.multi_hand_landmarks:\n",
    "                x = [None,None]\n",
    "                y=[None,None]\n",
    "                for result in results.multi_hand_landmarks[0].landmark:\n",
    "                    if x[0] is None or result.x < x[0]: x[0] = result.x\n",
    "                    if x[1] is None or result.x > x[1]: x[1] = result.x\n",
    "\n",
    "                    if y[0] is None or result.y < y[0]: y[0] = result.y\n",
    "                    if y[1] is None or result.y > y[1]: y[1] = result.y\n",
    "\n",
    "\n",
    "                if curr_time < round((time.time() - start_time)/3,1) and x[0] is not None:\n",
    "                        curr_time = round((time.time() - start_time)/3,1)\n",
    "                        try:\n",
    "                            test_image = get_landmark_dist_test(results, x[1]-x[0], y[1]-y[0])\n",
    "                            test_pred = np.argmax(clf.predict_proba(np.array([test_image])))\n",
    "                            test_probs = clf.predict_proba(np.array([test_image]))[0]\n",
    "                            print(\"Predicted:\",letters[test_pred], \", pred prob:\", max(test_probs), \", current index:\", easy_word_index, \", current time:\", curr_time)\n",
    "                            if max(test_probs) >= 0.8 or (max(test_probs) >= 0.6 and letters[test_pred] in ['p','r','u','v']):\n",
    "                                pred_letter = letters[test_pred].upper()\n",
    "                                if easy_word_index < len(easy_word) and pred_letter == easy_word[easy_word_index] and (easy_word_index == 0 or easy_word[easy_word_index] != easy_word[easy_word_index - 1]):\n",
    "                                    easy_word_user += pred_letter\n",
    "                                    easy_word_index += 1\n",
    "                                    location = results.multi_hand_landmarks[0].landmark[0].x\n",
    "                                if easy_word_index < len(easy_word) and pred_letter == easy_word[easy_word_index] and easy_word_index > 0 and easy_word[easy_word_index] == easy_word[easy_word_index - 1] and abs(location - results.multi_hand_landmarks[0].landmark[0].x) > 0.1:\n",
    "                                    easy_word_user += pred_letter\n",
    "                                    easy_word_index += 1\n",
    "                                    location = results.multi_hand_landmarks[0].landmark[0].x\n",
    "\n",
    "                            if easy_word_user == easy_word:\n",
    "                                time.sleep(0.5)\n",
    "                                easy_word = words[int(random()*len(words))].upper()\n",
    "                                easy_word_index = 0\n",
    "                                easy_word_user = ''\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "\n",
    "            try: \n",
    "                letter_help == 0\n",
    "            except:\n",
    "                frame[5:5+letter_help.shape[0],width-5-letter_help.shape[1]:width-5] = frame[5:5+letter_help.shape[0],width-5-letter_help.shape[1]:width-5]\n",
    "            \n",
    "            return frame\n",
    "            \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_frame():  # generate frame by frame from camera\n",
    "    global easy, cap\n",
    "    while True:\n",
    "        success, frame = cap.read() \n",
    "        if success:\n",
    "            if(easy):                \n",
    "                frame = easy_mode(frame)\n",
    "            elif(medium):                \n",
    "                frame = medium_mode(frame)\n",
    "   \n",
    "            try:\n",
    "                ret, buffer = cv2.imencode('.jpg', frame)\n",
    "                frame = buffer.tobytes()\n",
    "                yield (b'--frame\\r\\n'\n",
    "                       b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template(\"index.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    return Response(sign_frame(), mimetype='multipart/x-mixed-replace; boundary=frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/requests',methods=['POST','GET'])\n",
    "def mode():\n",
    "    global switch, easy, medium, hard, free\n",
    "    if request.method == 'POST':\n",
    "        if request.form.get('easy') == 'Easy':\n",
    "            easy= not easy\n",
    "            medium, hard, free =  0, 0, 0\n",
    "        elif  request.form.get('medium') == 'Medium':\n",
    "            medium=not medium\n",
    "            easy, hard, free =  0, 0, 0\n",
    "        elif  request.form.get('hard') == 'Hard':\n",
    "            hard=not hard\n",
    "            easy, medium, free =  0, 0, 0\n",
    "        elif  request.form.get('free') == 'Freestyle':\n",
    "            free=not free  \n",
    "            easy = 0\n",
    "            medium = 0\n",
    "            hard = 0\n",
    "        '''elif  request.form.get('switch') == 'Stop/Start':\n",
    "            \n",
    "            if switch:\n",
    "                switch=0\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                \n",
    "            else:\n",
    "                cap = cv2.VideoCapture(camera_max())\n",
    "                switch=1'''\n",
    "                          \n",
    "                 \n",
    "    elif request.method=='GET':\n",
    "        return render_template('index.html')\n",
    "    return render_template('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
